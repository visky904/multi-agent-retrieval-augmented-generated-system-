Multi-Agent RAG with Ollama (Local LLM System)

This project implements a Retrieval-Augmented Generation system using multiple local LLM agents via Ollama.

Architecture:

Retriever Agent – extracts relevant info

Reasoning Agent – performs deep analysis

Response Agent – generates clean output

Features:

Local LLMs (privacy + free)

Vector search with Chroma

Modular agent design
